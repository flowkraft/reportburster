homeserver:
  # The canonical homeserver domain name (for localhost development)
  server_name: localhost
  # Use the Docker Compose service hostname and internal port
  url: http://flowkraft-ai-crew-matrix-synapse:8008

user:
  mxid_localpart: kraftbot
  password: kraftbot

  # The name the bot uses as a display name and when it refers to itself.
  name: kraftbot

  # An optional path to an image file to be used as a custom avatar image.
  avatar: null

  encryption:
    # Passphrase for backing up and recovering the bot's encryption keys.
    # Generate with: openssl rand -base64 32
    recovery_passphrase: flowkraft-ai-crew-kraftbot-recovery-key-change-in-production

    # Flag to reset the encryption recovery passphrase.
    recovery_reset_allowed: false

# Command prefix
command_prefix: "!kraft"

room:
  # Whether the bot should send an introduction message after joining a room.
  post_join_self_introduction_enabled: true

access:
  # Space-separated list of MXID patterns which specify who is an admin.
  admin_patterns:
    - "@admin:localhost"
    - "@*:localhost"  # Allow all localhost users as admin for development

persistence:
  # This is unset here, because we expect the configuration to come from an environment variable (BAIBOT_PERSISTENCE_DATA_DIR_PATH).
  data_dir_path: null

  # Secret for encrypting the bot's session data (stored in data_dir_path).
  # Generate with: openssl rand -hex 32
  session_encryption_key: 9701cd109ed56770687dd8410f7d7371a4390dd3feb8ed721f189a0756c40098

  # Secret for encrypting bot configuration stored in Matrix's account data.
  # Generate with: openssl rand -hex 32
  config_encryption_key: a9f1df98d288802ead20a8be2c701a627eabd31cf3d9e2aea28867ccd7a4ded7

agents:
  # A list of statically-defined agents.
  # These point to the ai-crew frontend's OpenAI-compatible Letta endpoints
  static_definitions:
    # Example agents - customize these based on your actual Letta agents
    - id: ada-assistant
      provider: openai
      config:
        # Points to ai-crew frontend service within Docker network
        base_url: "http://flowkraft-ai-crew-frontend:3000/api/openai/ada-assistant/v1"
        api_key: ""   # Empty for local dev
        text_generation:
          model_id: "letta:ada-assistant"

    - id: kate-assistant
      provider: openai
      config:
        base_url: "http://flowkraft-ai-crew-frontend:3000/api/openai/kate-assistant/v1"
        api_key: ""
        text_generation:
          model_id: "letta:kate-assistant"

    # Uncomment and configure additional agents as needed:
    # - id: custom-agent
    #   provider: openai
    #   config:
    #     base_url: "http://flowkraft-ai-crew-frontend:3000/api/openai/custom-agent/v1"
    #     api_key: ""
    #     text_generation:
    #       model_id: "letta:custom-agent"

# Initial global configuration. This only affects the first run of the bot.
initial_global_config:
  handler:
    catch_all: null
    text_generation: "static/ada-assistant"
    text_to_speech: null
    speech_to_text: null
    image_generation: null

  # Space-separated list of MXID patterns which specify who can use the bot.
  # For localhost development, allow all users
  user_patterns:
    - "@*:localhost"

# Controls logging.
logging: warn,mxlink=debug,baibot=debug
